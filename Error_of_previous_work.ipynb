{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this document, we will point out the experimental mistakes in the previous work of :  Rodrigues, Filipe, Ioulia Markou, and Francisco C. Pereira. \"Combining time-series and textual data for taxi demand prediction in event areas: A deep learning approach.\" Information Fusion 49 (2019): 120-129."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code is copied from their previous experiment:  https://github.com/fmpr/Combining-TimeSeries-TextData/blob/master/barclays_fc/run_experiments.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weather data...\n",
      "loading events data...\n",
      "loading taxi data (and merging and detrending)...\n",
      "building lags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi-pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:149: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\msi-pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:150: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\msi-pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:151: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\msi-pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:153: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\msi-pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:154: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\msi-pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:155: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\msi-pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:156: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\msi-pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:159: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\msi-pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:160: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\msi-pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:161: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\msi-pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:162: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from sklearn import datasets, linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import BatchNormalization, Input, Embedding, Concatenate, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.layers import merge, Concatenate, Permute, RepeatVector, Reshape\n",
    "from keras.models import Sequential, Model\n",
    "import keras.backend as K\n",
    "import statsmodels.formula.api as smf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# prevent tensorflow from allocating the entire GPU memory at once\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "# ---------------------------------------- GLOBAL PARAMETERS\n",
    "\n",
    "NUM_LAGS = 10\n",
    "sel = [0,2,4,5,7,8,9] # weather features to use\n",
    "\n",
    "# word embeddings parameters\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 600 #1000\n",
    "MAX_NB_WORDS = 5000 #20000\n",
    "EMBEDDING_DIM = 300 #300\n",
    "\n",
    "\n",
    "# ---------------------------------------- Load weather data\n",
    "print(\"loading weather data...\")\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"D:/pycharmworkspace/GNN/release_code_and_datasets/central_park_weather.csv\")\n",
    "df = df.set_index(\"date\")\n",
    "\n",
    "# replace predefined values with NaN\n",
    "df = df.replace(99.99, np.nan)\n",
    "df = df.replace(999.9, np.nan)\n",
    "df = df.replace(9999.9, np.nan)\n",
    "\n",
    "# replace NaN with 0 for snow depth\n",
    "df[\"snow_depth\"] = df[\"snow_depth\"].fillna(0)\n",
    "\n",
    "# do interpolation for the remaining NaNs\n",
    "df = df.interpolate()\n",
    "\n",
    "# standardize data\n",
    "removed_mean = df.mean()\n",
    "removed_std = df.std()\n",
    "weather = (df - removed_mean) / removed_std\n",
    "\n",
    "\n",
    "# ---------------------------------------- Load events data\n",
    "print(\"loading events data...\")\n",
    "\n",
    "events = pd.read_csv(\"D:/pycharmworkspace/GNN/release_code_and_datasets/barclays_events_preprocessed.tsv\", sep=\"\\t\")\n",
    "events.head()\n",
    "\n",
    "events['start_time'] = pd.to_datetime(events['start_time'], format='%Y-%m-%d %H:%M')\n",
    "events['date'] = events['start_time'].dt.strftime(\"%Y-%m-%d\")\n",
    "events = events[[\"date\",\"start_time\",\"title\",\"url\",\"description\"]]\n",
    "\n",
    "\n",
    "# ---------------------------------------- Load taxi data (and merge with others and detrend)\n",
    "print(\"loading taxi data (and merging and detrending)...\")\n",
    "\n",
    "df = pd.read_csv(\"D:/pycharmworkspace/GNN/release_code_and_datasets/pickups_barclays_center_0.003.csv\")\n",
    "\n",
    "df_sum = pd.DataFrame(df.groupby(\"date\")[\"pickups\"].sum())\n",
    "df_sum[\"date\"] = df_sum.index\n",
    "df_sum.index = pd.to_datetime(df_sum.index, format='%Y-%m-%d %H:%M')\n",
    "df_sum[\"dow\"] = df_sum.index.weekday\n",
    "\n",
    "# add events information\n",
    "event_col = np.zeros((len(df_sum)))\n",
    "late_event = np.zeros((len(df_sum)))\n",
    "really_late_event = np.zeros((len(df_sum)))\n",
    "event_desc_col = []\n",
    "for i in range(len(df_sum)):\n",
    "    if df_sum.iloc[i].date in events[\"date\"].values:\n",
    "        event_col[i] = 1\n",
    "        event_descr = \"\"\n",
    "        for e in events[events.date == df_sum.iloc[i].date][\"description\"]:\n",
    "            event_descr += str(e) + \" \"\n",
    "        event_desc_col.append(event_descr)\n",
    "        for e in events[events.date == df_sum.iloc[i].date][\"start_time\"]:\n",
    "            if e.hour >= 20:\n",
    "                late_event[i] = 1\n",
    "            if e.hour >= 21:\n",
    "                really_late_event[i] = 1\n",
    "    else:\n",
    "        event_desc_col.append(\"None\")\n",
    "\n",
    "df_sum[\"event\"] = event_col\n",
    "df_sum[\"late_event\"] = late_event\n",
    "df_sum[\"really_late_event\"] = really_late_event\n",
    "df_sum[\"event_desc\"] = event_desc_col\n",
    "df_sum[\"event_next_day\"] = pd.Series(df_sum[\"event\"]).shift(-1)\n",
    "df_sum[\"late_event_next_day\"] = pd.Series(df_sum[\"late_event\"]).shift(-1)\n",
    "df_sum[\"really_late_event_next_day\"] = pd.Series(df_sum[\"really_late_event\"]).shift(-1)\n",
    "df_sum[\"event_next_day_desc\"] = pd.Series(df_sum[\"event_desc\"]).shift(-1)\n",
    "\n",
    "# merge with weather data\n",
    "df_sum = df_sum.join(weather, how='inner')\n",
    "df_sum.head()\n",
    "\n",
    "# keep only data after 2013\n",
    "START_YEAR = 2013\n",
    "df_sum = df_sum.loc[df_sum.index.year >= START_YEAR]\n",
    "df_sum.head()\n",
    "\n",
    "df_sum[\"year\"] = df_sum.index.year\n",
    "\n",
    "trend_mean = df_sum[df_sum.index.year < 2015].groupby([\"dow\"]).mean()[\"pickups\"]\n",
    "\n",
    "#trend_std = df_sum.groupby([\"year\"]).std()[\"pickups\"]\n",
    "trend_std = df_sum[\"pickups\"].std()\n",
    "\n",
    "# build vectors with trend to remove and std\n",
    "trend = []\n",
    "std = []\n",
    "for ix, row in df_sum.iterrows():\n",
    "    trend.append(trend_mean[row.dow])\n",
    "    #std.append(trend_std[row.year])\n",
    "    std.append(trend_std)\n",
    "\n",
    "df_sum[\"trend\"] = trend\n",
    "df_sum[\"std\"] = std\n",
    "\n",
    "# detrend data\n",
    "df_sum[\"detrended\"] = (df_sum[\"pickups\"] - df_sum[\"trend\"]) / df_sum[\"std\"]\n",
    "\n",
    "\n",
    "# ---------------------------------------- Build lags and features\n",
    "print(\"building lags...\")\n",
    "\n",
    "lags = pd.concat([pd.Series(df_sum[\"detrended\"]).shift(x) for x in range(0,NUM_LAGS)],axis=1).as_matrix()\n",
    "event_feats = np.concatenate([df_sum[\"event_next_day\"].as_matrix()[:,np.newaxis],\n",
    "                             df_sum[\"late_event\"].as_matrix()[:,np.newaxis],\n",
    "                             #df_sum[\"late_event_next_day\"].as_matrix()[:,np.newaxis],\n",
    "                             df_sum[\"really_late_event\"].as_matrix()[:,np.newaxis],\n",
    "                             df_sum[\"really_late_event_next_day\"].as_matrix()[:,np.newaxis]], axis=1)\n",
    "lags_event_feats = pd.concat([pd.Series(df_sum[\"event_next_day\"]).shift(x) for x in range(0,NUM_LAGS)],axis=1).as_matrix()\n",
    "event_texts = df_sum[\"event_next_day_desc\"].as_matrix()\n",
    "weather_feats = df_sum[['min_temp', 'max_temp', 'wind_speed',\n",
    "       'wind_gust', 'visibility', 'pressure', 'precipitation',\n",
    "       'snow_depth', 'fog', 'rain_drizzle', 'snow_ice', 'thunder']].as_matrix()\n",
    "preds = pd.Series(df_sum[\"detrended\"]).shift(-1).as_matrix()\n",
    "trends = df_sum[\"trend\"].as_matrix()\n",
    "stds = df_sum[\"std\"].as_matrix()\n",
    "\n",
    "lags = lags[NUM_LAGS:-1,:]\n",
    "event_feats = event_feats[NUM_LAGS:-1,:]\n",
    "lags_event_feats = lags_event_feats[NUM_LAGS:-1,:]\n",
    "event_texts = event_texts[NUM_LAGS:-1]\n",
    "weather_feats = weather_feats[NUM_LAGS:-1,:]\n",
    "preds = preds[NUM_LAGS:-1]\n",
    "trends = trends[NUM_LAGS:-1]\n",
    "stds = stds[NUM_LAGS:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train/val/test split...\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------- Train/test split\n",
    "print(\"loading train/val/test split...\")\n",
    "\n",
    "i_train = 365*2-90 # 2013 and 2014\n",
    "i_val = 365*2\n",
    "i_test = -1 # 2015 and 2016 (everything else)\n",
    "\n",
    "lags_train = lags[:i_train,:] # time series lags\n",
    "event_feats_train = event_feats[:i_train,:] # event/no_event\n",
    "lags_event_feats_train = lags_event_feats[:i_train,:] # lags for event/no_event\n",
    "event_texts_train = event_texts[:i_train] # event text descriptions\n",
    "weather_feats_train = weather_feats[:i_train,:] # weather data\n",
    "y_train = preds[:i_train] # target values\n",
    "\n",
    "lags_val = lags[i_train:i_val,:] # time series lags\n",
    "event_feats_val = event_feats[i_train:i_val,:] # event/no_event\n",
    "lags_event_feats_val = lags_event_feats[i_train:i_val,:] # lags for event/no_event\n",
    "event_texts_val = event_texts[i_train:i_val] # event text descriptions\n",
    "weather_feats_val = weather_feats[i_train:i_val,:] # weather data\n",
    "y_val = preds[i_train:i_val] # target values\n",
    "\n",
    "lags_test = lags[i_val:i_test,:]\n",
    "event_feats_test = event_feats[i_val:i_test,:]\n",
    "lags_event_feats_test = lags_event_feats[i_val:i_test,:]\n",
    "event_texts_test = event_texts[i_val:i_test]\n",
    "weather_feats_test = weather_feats[i_val:i_test,:]\n",
    "y_test = preds[i_val:i_test]\n",
    "trend_test = trends[i_val:i_test]\n",
    "std_test = stds[i_val:i_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------- Evaluation functions\n",
    "\n",
    "def compute_error(trues, predicted):\n",
    "    corr = np.corrcoef(predicted, trues)[0,1]\n",
    "    mae = np.mean(np.abs(predicted - trues))\n",
    "    rae = np.sum(np.abs(predicted - trues)) / np.sum(np.abs(trues - np.mean(trues)))\n",
    "    rmse = np.sqrt(np.mean((predicted - trues)**2))\n",
    "    rrse = np.sqrt(np.sum((predicted - trues)**2) / np.sum((trues - np.mean(trues))**2))\n",
    "    mape = np.mean(np.abs((predicted - trues) / trues)) * 100\n",
    "    r2 = max(0, 1 - np.sum((predicted - trues)**2) / np.sum((trues - np.mean(trues))**2))\n",
    "    return corr, mae, rae, rmse, rrse, mape, r2\n",
    "\n",
    "\n",
    "def compute_error_filtered(trues, predicted, filt):\n",
    "    trues = trues[filt]\n",
    "    predicted = predicted[filt]\n",
    "    corr = np.corrcoef(predicted, trues)[0,1]\n",
    "    mae = np.mean(np.abs(predicted - trues))\n",
    "    mse = np.mean((predicted - trues)**2)\n",
    "    rae = np.sum(np.abs(predicted - trues)) / np.sum(np.abs(trues - np.mean(trues)))\n",
    "    rmse = np.sqrt(np.mean((predicted - trues)**2))\n",
    "    r2 = max(0, 1 - np.sum((trues-predicted)**2) / np.sum((trues - np.mean(trues))**2))\n",
    "    return corr, mae, mse, rae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running linear regression with just lags...\n",
      "MAE:  119.619\tRMSE: 164.510\tR2:   0.448\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------- Linear regression baseline (just lags)\n",
    "\n",
    "# linear regression (just lags)\n",
    "print(\"\\nrunning linear regression with just lags...\")\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(lags_train, y_train)\n",
    "preds_lr = regr.predict(lags_test)\n",
    "preds_lr = preds_lr * std_test + trend_test\n",
    "y_true = y_test * std_test + trend_test\n",
    "corr, mae, rae, rmse, rrse, mape, r2 = compute_error(y_true, preds_lr)\n",
    "print(\"MAE:  %.3f\\tRMSE: %.3f\\tR2:   %.3f\" % (mae, rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1201.93269231,  678.25274725,  963.78095238,  707.92783883,\n",
       "        760.98076923, 1242.40384615, 1040.72115385,  916.93269231,\n",
       "        611.25274725,  594.78095238,  671.92783883,  633.98076923,\n",
       "        906.40384615,  986.72115385,  647.93269231,  211.25274725,\n",
       "        588.78095238,  662.92783883, 1217.98076923, 1224.40384615,\n",
       "       1080.72115385, 1146.93269231,  717.25274725,  628.78095238,\n",
       "        766.92783883, 1111.98076923, 1018.40384615, 1061.72115385,\n",
       "        993.93269231,  668.25274725,  761.78095238,  912.92783883,\n",
       "       1045.98076923, 1289.40384615, 1475.72115385, 1330.93269231,\n",
       "        733.25274725,  740.78095238, 1154.92783883, 1094.98076923,\n",
       "       1100.40384615, 1163.72115385, 1018.93269231,  828.25274725,\n",
       "        784.78095238, 1035.92783883, 1017.98076923, 1180.40384615,\n",
       "       1038.72115385, 1291.93269231,  757.25274725, 1099.78095238,\n",
       "        760.92783883, 1127.98076923, 1261.40384615, 1235.72115385,\n",
       "        907.93269231, 1153.25274725,  815.78095238, 1015.92783883,\n",
       "       1058.98076923, 1275.40384615, 1204.72115385,  881.93269231,\n",
       "        755.25274725,  701.78095238,  738.92783883,  995.98076923,\n",
       "       1086.40384615, 1153.72115385, 1210.93269231,  769.25274725,\n",
       "        812.78095238, 1011.92783883, 1165.98076923, 1165.40384615,\n",
       "       1207.72115385,  931.93269231, 1045.25274725,  795.78095238,\n",
       "        936.92783883, 1085.98076923, 1063.40384615,  999.72115385,\n",
       "       1150.93269231,  818.25274725, 1069.78095238,  798.92783883,\n",
       "       1103.98076923, 1181.40384615, 1595.72115385, 1468.93269231,\n",
       "        617.25274725,  955.78095238,  807.92783883,  878.98076923,\n",
       "        956.40384615, 1082.72115385,  830.93269231,  602.25274725,\n",
       "        682.78095238,  793.92783883,  814.98076923, 1021.40384615,\n",
       "        974.72115385, 1221.93269231,  659.25274725,  680.78095238,\n",
       "        725.92783883, 1242.98076923, 1093.40384615, 1093.72115385,\n",
       "        920.93269231,  759.25274725,  739.78095238,  838.92783883,\n",
       "        773.98076923, 1068.40384615, 1055.72115385,  903.93269231,\n",
       "        774.25274725,  707.78095238,  814.92783883,  762.98076923,\n",
       "        960.40384615,  994.72115385,  868.93269231,  612.25274725,\n",
       "        696.78095238,  763.92783883,  699.98076923,  686.40384615,\n",
       "        921.72115385,  968.93269231,  872.25274725,  703.78095238,\n",
       "        793.92783883,  863.98076923, 1064.40384615, 1219.72115385,\n",
       "        968.93269231,  772.25274725,  730.78095238,  799.92783883,\n",
       "        762.98076923, 1068.40384615, 1130.72115385,  896.93269231,\n",
       "        627.25274725,  644.78095238,  830.92783883,  748.98076923,\n",
       "        905.40384615, 1347.72115385,  905.93269231,  618.25274725,\n",
       "        898.78095238,  752.92783883,  806.98076923,  904.40384615,\n",
       "       1010.72115385,  908.93269231,  700.25274725,  621.78095238,\n",
       "        945.92783883,  905.98076923, 1287.40384615, 1119.72115385,\n",
       "       1073.93269231,  866.25274725,  754.78095238,  823.92783883,\n",
       "        799.98076923,  649.40384615,  920.72115385,  878.93269231,\n",
       "        651.25274725,  725.78095238,  910.92783883, 1030.98076923,\n",
       "       1058.40384615, 1219.72115385,  962.93269231,  631.25274725,\n",
       "        649.78095238,  699.92783883,  570.98076923,  895.40384615,\n",
       "       1114.72115385,  931.93269231,  671.25274725,  646.78095238,\n",
       "        794.92783883,  702.98076923,  782.40384615, 1135.72115385,\n",
       "        979.93269231,  632.25274725,  656.78095238,  705.92783883,\n",
       "        784.98076923,  956.40384615, 1166.72115385,  861.93269231,\n",
       "        626.25274725,  626.78095238,  720.92783883,  662.98076923,\n",
       "        866.40384615, 1083.72115385,  844.93269231,  705.25274725,\n",
       "        874.78095238,  836.92783883,  789.98076923,  930.40384615,\n",
       "       1017.72115385,  927.93269231,  658.25274725,  736.78095238,\n",
       "        757.92783883,  787.98076923, 1051.40384615, 1333.72115385,\n",
       "       1209.93269231,  695.25274725,  605.78095238,  725.92783883,\n",
       "        709.98076923,  890.40384615, 1008.72115385,  942.93269231,\n",
       "        667.25274725,  621.78095238,  776.92783883,  764.98076923,\n",
       "        826.40384615,  992.72115385, 1170.93269231,  612.25274725,\n",
       "        636.78095238,  805.92783883,  749.98076923, 1064.40384615,\n",
       "       1076.72115385,  901.93269231,  653.25274725,  628.78095238,\n",
       "        719.92783883,  781.98076923, 1079.40384615, 1248.72115385,\n",
       "       1014.93269231,  553.25274725,  753.78095238,  663.92783883,\n",
       "        897.98076923, 1129.40384615, 1129.72115385,  992.93269231,\n",
       "        614.25274725,  705.78095238,  817.92783883,  840.98076923,\n",
       "       1034.40384615,  989.72115385,  980.93269231,  638.25274725,\n",
       "        610.78095238,  833.92783883, 1091.98076923,  972.40384615,\n",
       "       1017.72115385,  901.93269231,  687.25274725,  752.78095238,\n",
       "        868.92783883,  925.98076923, 1219.40384615, 1183.72115385,\n",
       "        945.93269231,  964.25274725,  847.78095238,  880.92783883,\n",
       "       1387.98076923, 1036.40384615, 1170.72115385, 1027.93269231,\n",
       "        677.25274725, 1069.78095238, 1045.92783883,  955.98076923,\n",
       "        957.40384615, 1171.72115385, 1035.93269231,  799.25274725,\n",
       "        608.78095238,  703.92783883, 1098.98076923,  984.40384615,\n",
       "       1154.72115385,  875.93269231,  806.25274725,  693.78095238,\n",
       "        691.92783883,  854.98076923, 1152.40384615, 1122.72115385,\n",
       "        928.93269231,  897.25274725, 1037.78095238, 1194.92783883,\n",
       "       1163.98076923, 1161.40384615, 1223.72115385, 1105.93269231,\n",
       "        828.25274725, 1030.78095238,  814.92783883, 1017.98076923,\n",
       "        930.40384615, 1155.72115385, 1104.93269231,  925.25274725,\n",
       "        979.78095238,  865.92783883, 1064.98076923, 1373.40384615,\n",
       "       1367.72115385,  938.93269231,  909.25274725,  690.78095238,\n",
       "       1069.92783883,  814.98076923, 1122.40384615, 1228.72115385,\n",
       "       1207.93269231,  974.25274725, 1115.78095238, 1002.92783883,\n",
       "       1157.98076923, 1477.40384615, 1210.72115385, 1351.93269231,\n",
       "        955.25274725, 1165.78095238, 1135.92783883,  324.98076923,\n",
       "        872.40384615,  998.72115385, 1171.93269231,  725.25274725,\n",
       "        827.78095238, 1261.92783883,  939.98076923,  891.40384615,\n",
       "       1085.72115385, 1237.93269231,  666.25274725,  859.78095238,\n",
       "        931.92783883,  943.98076923,  840.40384615, 1020.72115385,\n",
       "       1235.93269231,  793.25274725, 1167.78095238, 1036.92783883,\n",
       "       1078.98076923, 1020.40384615, 1443.72115385, 1002.93269231,\n",
       "        650.25274725, 1055.78095238, 1092.92783883, 1385.98076923,\n",
       "         82.40384615,  742.72115385, 1084.93269231,  920.25274725,\n",
       "       1026.78095238,  779.92783883,  788.98076923, 1223.40384615,\n",
       "       1074.72115385, 1127.93269231,  832.25274725,  893.78095238,\n",
       "        803.92783883, 1163.98076923, 1333.40384615, 1290.72115385,\n",
       "       1144.93269231,  668.25274725, 1091.78095238, 1268.92783883,\n",
       "       1099.98076923, 1749.40384615, 1376.72115385, 1401.93269231,\n",
       "        691.25274725,  831.78095238, 1108.92783883, 1393.98076923,\n",
       "       1305.40384615, 1468.72115385,  918.93269231,  770.25274725,\n",
       "        785.78095238,  916.92783883,  909.98076923, 1210.40384615,\n",
       "       1101.72115385,  916.93269231,  772.25274725,  808.78095238,\n",
       "        909.92783883,  908.98076923, 1215.40384615, 1332.72115385,\n",
       "        901.93269231,  955.25274725,  785.78095238,  902.92783883,\n",
       "       1120.98076923, 1406.40384615, 1347.72115385, 1201.93269231,\n",
       "        925.25274725,  708.78095238,  811.92783883, 1191.98076923,\n",
       "       1362.40384615, 1252.72115385, 1161.93269231,  927.25274725,\n",
       "        813.78095238, 1099.92783883,  898.98076923, 1421.40384615,\n",
       "       1258.72115385, 1265.93269231,  874.25274725, 1059.78095238,\n",
       "       1091.92783883,  839.98076923, 1159.40384615, 1212.72115385,\n",
       "       1164.93269231,  915.25274725,  694.78095238,  785.92783883,\n",
       "       1201.98076923, 1502.40384615, 1282.72115385, 1154.93269231,\n",
       "        997.25274725, 1107.78095238,  835.92783883,  984.98076923,\n",
       "       1209.40384615, 1277.72115385,  980.93269231,  685.25274725,\n",
       "        851.78095238,  746.92783883,  762.98076923, 1194.40384615,\n",
       "       1371.72115385, 1272.93269231,  822.25274725,  656.78095238,\n",
       "        744.92783883,  867.98076923,  946.40384615, 1054.72115385,\n",
       "        877.93269231,  928.25274725,  965.78095238, 1031.92783883,\n",
       "       1120.98076923,  995.40384615, 1321.72115385,  848.93269231,\n",
       "        604.25274725,  567.78095238,  787.92783883,  720.98076923,\n",
       "       1049.40384615, 1200.72115385,  865.93269231,  864.25274725,\n",
       "        760.78095238,  785.92783883,  799.98076923, 1546.40384615,\n",
       "       1285.72115385,  874.93269231,  602.25274725,  686.78095238,\n",
       "        791.92783883,  784.98076923, 1049.40384615, 1118.72115385,\n",
       "       1137.93269231,  628.25274725,  789.78095238,  821.92783883,\n",
       "        728.98076923,  952.40384615, 1081.72115385,  983.93269231,\n",
       "        642.25274725,  710.78095238,  717.92783883,  751.98076923,\n",
       "       1012.40384615, 1097.72115385,  906.93269231,  847.25274725,\n",
       "        947.78095238,  788.92783883,  698.98076923,  842.40384615,\n",
       "       1088.72115385,  901.93269231,  618.25274725,  668.78095238,\n",
       "        993.92783883,  927.98076923, 1024.40384615, 1188.72115385,\n",
       "        943.93269231,  650.25274725,  581.78095238])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that the ground truth taxi demand  has become a decimal after preprocessing. Actually this is wrong, because the taxi demand  is an integer in the original data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This error is actually caused by the data normalization process. Specifically, preds is not aligned with trends and stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This error will change the ground truth taxi demand  and therefore affect the value of evaluation metrics. This error is fatal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In our experiment, this error has been corrected, and Taxi Demand Forecasting Based on the Multi-modal Information Fusion Graph Neural Network has been proposed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
